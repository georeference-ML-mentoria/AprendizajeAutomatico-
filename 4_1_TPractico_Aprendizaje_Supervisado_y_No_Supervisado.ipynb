{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRWQndQrG6nT"
   },
   "source": [
    "<center>\n",
    "<h4>Diplodatos 2020 - FaMAF - UNC</h4>\n",
    "<h1>Procesamiento de datos georeferenciados</h1>\n",
    "<h3>Aprendizaje Supervisado</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cslNL1iOG6nV"
   },
   "source": [
    "### Introducción\n",
    "\n",
    "En el siguiente trabajo profundizaremos en el proceso de entrenamiento del modelo centrandonos en diferentes formas de seleccion de variables y tuning de hiperparametros.\n",
    "\n",
    "Para esto construiremos sobre el conocimiento obtenido de los practicos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEt7u6VHG6nd"
   },
   "source": [
    "# Aprendizaje Automático Supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LgIRJLHMQUb"
   },
   "source": [
    "## Carga y particion de los datos, en training y test\n",
    "\n",
    "Antes de comenzar con el analisis debemos partir nuestro dataset en training y test sets.\n",
    "Carguen el dataset utilizado en el practico anterior, realizen la particion y apliquen un pipeline de preprocesamiento en base a lo realizado en el practico anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PQ-v9egMQiz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hm69f-yVM8tb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DItM-OERM8wB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMEJ2NvgLGqW"
   },
   "source": [
    "## Baseline\n",
    "\n",
    "En este practico estaremos utilizando nuevamente un modelo XGBoost, ya que nos permite obtener buenos resultados de manera rapida y ademas cuenta con numerosos hiperparametros que podremos ajustar para optimizar su performance.\n",
    "\n",
    "Para comenzar definiremos un baseline utilizando los hiperparametros por defecto.\n",
    "\n",
    "Entrene un modelo XGBoost basico, utilizando los hiperparametros por defecto, seleccione una metrica de error y presente el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3pqwbB0LF5i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VT7Xh-vaNZe6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncjW50mLG6nf"
   },
   "source": [
    "## Seleccion de variables\n",
    "\n",
    "La seleccion de variables es un proceso a traves del cual se intentan distinguir las variables que aportan valor de prediccion de las que no, y de esta forma quedarnos solamente con aquellas que impacten positivamente en nuestro algoritmo.\n",
    "\n",
    "Esto nos traera multiples beneficios, al simplificar el modelo reducimos el riesgo de overfitting, disminuimos el costo computacional de entrenamiento y prediccion y reducimos el ruido introducido por las variables de poco valor.\n",
    "\n",
    "Existen diversas formas de llevar a cabo este proyecto:\n",
    "  - Filtros o Reglas: Se especifica alguna metrica o valor estadistico y se eliminan las features que no lo cumplan. Ej: Correlacion maxima entre variables, correlacion minima con la variable de salida, colinealidad entre variables, cantidad de valores nulos.\n",
    "\n",
    "  - Wrapper Base: Son metodos que se plantean como problemas de busqueda, como por ejemplo la eliminacion recursiva de variables.\n",
    "\n",
    "  - Metodos embebidos: Algunos metodos de estimacion poseen procesos internos de clasificacion de variables, en donde se le asigna un nivel de importancia a cada una de ellas que puede luego ser utilizado para conocer su importancia. Ejemplos clasicos son los coeficientes de la regresion de Lasso o el feature importance en implementaciones basadas en arboles como XGBoost.\n",
    "\n",
    "En base al baseline calculado en el punto anterior comience seleccionando las 50 variables mas importantes en base a la informacion provista por XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zm43gk9ERkkZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHUcJdAyRkxe"
   },
   "source": [
    "A partir del punto anterior calcule el error para diferentes cantidades de variables, realize un grafico de numero de variables vs error, seleccione el valor de mejor performance y justique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPluDiPBRlHL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8fgdPh2URqB"
   },
   "source": [
    "Genere un nuevo dataset que contenga solamente las variables seleccionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cg0m3cjG6nf"
   },
   "source": [
    "## Tuning de hiperparametros\n",
    "\n",
    "Existen varias formas de hacer tuneo de hiperparametros, la mejor opcion dependera del costo computacional del modelo y las limitacion en tiempos o recursos que tengamos.\n",
    "\n",
    "Lo primero que debemos definir es un espacio de busqueda, en nuestro caso el modelo cuenta con numerosos hiperparametros, pero utilizarlos a todos representaria un espacio de busqueda muy grande y por ende un costo computacional muy grande.\n",
    "\n",
    "Consultando la documentacion seleccione entre 3 y 5 parametros de XGBoost y defina un espacio de busqueda que pueda ser utilizado por sklearn.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_nz8KccZ8op"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-g8afD4lZ9Bb"
   },
   "source": [
    "\n",
    "### Random search\n",
    "\n",
    "Una opcion es una busqueda de hiperparametros sobre un espacio de forma aleatorea. Esta opcion en un principio no nos garantiza encontrar la mejor combinacion sin embargo tiene la ventaja de necesitar muchas menos iteraciones.\n",
    "\n",
    "Utilize la funcion de sklearn.model_selection.RandomizedSearchCV para realizar una busqueda de hiperpatametros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qavZpSpaGqO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76dT62IVaHAu"
   },
   "source": [
    "### Grid search\n",
    "\n",
    "Cuando queremos agotar las posibilidades de busqueda podemos realizar una busqueda de todas las combinaciones de parametros posibles, esto se denomina Grid Search.\n",
    "\n",
    "Utilize la funcion de sklearn.model_selection.GridSearchCV para realizar una busqueda de hiperpatametros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SE_Zmmwbaojm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5KLZi6ja6P6"
   },
   "source": [
    "### Metodos Avanzados, Optimizacion Bayesiana.\n",
    "\n",
    "Existen metodos mas avanzados de busqueda de hiperparametros, uno de ellos utiliza metodos bayesianos para dirigir la busqueda de modo que esta se realize de manera mas eficiente.\n",
    "\n",
    "Una forma de implementar esto facilmente en python es utilizando la libreria hyperopt. A continuacion se presenta un template para utilizar las misma.\n",
    "\n",
    "Pueden encontrar mas informacion en: \n",
    "https://hyperopt.github.io/hyperopt/?source=post_page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eA_f7WDLbhqW"
   },
   "outputs": [],
   "source": [
    "# import\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "# Definicion de espacio de busqueda\n",
    "space={'max_depth': hp.quniform(\"max_depth\", x, x, x1),\n",
    "        'gamma': hp.uniform ('gamma', x,x),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', x,x,x),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', x,x),\n",
    "        'n_estimators': x,\n",
    "        'seed': 0\n",
    "    }\n",
    "\n",
    "# Debemos generar una funcion objetivo que luego pasaremos al optimizar para minimizar\n",
    "# Observar que la funcion retorna el valor negativo de accuracy, ya que como\n",
    "# mencionamos el optimizador 'minimizara' ese valor\n",
    "\n",
    "def objective(space):\n",
    "    clf= xgb.XGBClassifier(\n",
    "                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']))\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10, verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }\n",
    "\n",
    "# Correr Optimizacion\n",
    "trials = Trials()\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOGSm-n-dmZS"
   },
   "source": [
    "## Comparacion\n",
    "\n",
    "Realize una tabla comparativa de los resultados obtenidos entre:\n",
    "\n",
    "- Modelo con hiperparametros por default sin seleccion de variables\n",
    "- Modelo con hiperparametros por default con seleccion de variables\n",
    "- Modelo con optimizacion de hiperparametros por cada metodo\n",
    "\n",
    "En base a los resultados exponga sus observacion relacionada tanto con la performance del modelo como de los tiempos de ejecucion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HoXI1T65e_lk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5hfsfnEfu4z"
   },
   "source": [
    "# Aprendizaje Automático No Supervisado\n",
    "\n",
    "### Clusterizacion como metodo de generacion de features\n",
    "\n",
    "Vamos a utilizar a la clusterización como método de generacion de features y posteriormente vamos a correr los modelos de predicción.\n",
    "\n",
    "Basandose en el algoritmo de KMeans, aplique el metodo de codo (elbow) para estimar la cantidad optima de clusters. \n",
    "\n",
    "(Opcional) En caso de que la clusterizacion este demorando mucho en ejecutarse puede aplicarse PCA en un paso previo para disminuir las dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rh04QSsgo15"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7YXXxMegpDX"
   },
   "source": [
    "Realizar la predicción del cluster del conjunto de validación.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHtbCgT-gpMi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIwTiogQgpVW"
   },
   "source": [
    "Integre los clusters al dataset de training y vuelva a correr a entrenar el algoritmo de deteccion de mejor rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zY6QIT-gpdE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7BPkcMQhZcY"
   },
   "source": [
    "Compare los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lyfryL5kUk0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4_1_TPractico - Aprendizaje Supervisado y No Supervisado.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
